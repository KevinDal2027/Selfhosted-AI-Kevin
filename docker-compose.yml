version: '3.8'
services:
  ai-frontend:
    build: ./frontend
    ports: ["3000:3000"]
    restart: unless-stopped
    depends_on: [ai-backend]
    env_file:
      - ./frontend/.env
  ai-backend:
    build: ./backend
    ports: 
      - "3001:3001"
    restart: unless-stopped
    depends_on: [ollama]
    env_file:
      - ./backend/.env
    environment:
      - OLLAMA_HOST=http://ollama:11434
  ollama:
    build:
      context: ./kevin-ollama
      dockerfile: Dockerfile
    ports:
      - "11434:11434"
    restart: unless-stopped
